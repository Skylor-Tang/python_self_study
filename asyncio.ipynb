{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：\n",
    "当前Python的并发解决方案很多，包括tornado、gevent、twisted、asyncio\n",
    "\n",
    "tornado、gevent是采用了Python提供的生成器来实现的，gevent又是通过底层的c语言实现的协程来完成的，\n",
    "gevent最大的问题是采用了猴子补丁对很多Python内置库进行补丁，使用起来方便，但是这样很多内部的异常就很难捕捉到\n",
    "tornado兼容2和3\n",
    "\n",
    "asyncio 是目前主推的核心模块\n",
    "\n",
    "协程是由程序员自己调度，asyncio主要功能就是实现对协程的自动调度（即是一个帮助程序员调度协程的框架），使得能够完成协程调度的同时，\n",
    "能够像同步编码的方式去编写异步的代码。\n",
    "\n",
    "阻塞io --->  异步非阻塞的编码方式\n",
    "\n",
    "了解协程调度的方式达到自己编写并发库的目的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python 中解决异步io 高并发编程的核心模块（）   Python3.4后引入   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 什么时候用协程，     异步io   async"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>asyncio可以像线程池那样理解为协程池，但是asyncio中提交的都是协程函数的调用（即带()的调用，协程函数调用的返回值为协程对象），而线程池中是提交的线程对象（不需要使用调用）</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 事件编程"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "包含各种特定系统实现的模块化事件循环  ----  使得在各个系统下都可以使用asyncio进行异步编程\n",
    "传输和协议抽象\n",
    "对TCP、UDP、SSL、子进程、延时调用以及其他的具体支持\n",
    "模仿futures模块但适用于事件循环使用的Future类\n",
    "基于yield from的协议和任务，可以让你用顺序的方式编写并发代码\n",
    "必须使用一个将产生阻塞IO的调用时，有接口可以把这个事件转移到线程池\n",
    "\n",
    "虽然主要功能是用于做携程调度的，但实际上也可以将多线程和多进程融合进来\n",
    "\n",
    "模仿threading模块中的同步原语、可以用在当线程内的协程之间\n",
    "\n",
    "\n",
    "虽然可以用协程，但是协程需要去搭配事件循环才能实现相应的效果，而使用asyncio可以帮我们完成事件循环的操作\n",
    "事件循环是模仿操作系统完成多线程的调度那样完成对协程的调度\n",
    "\n",
    "协程是两个之间的交流， 但是使用asyncio则是使多个进行交流，像多线程那样\n",
    "协程虽然也可以多个，但是要手动回调之类的，而使用asyncio提供了事件循环，自动帮我们完成回调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 协程编码模式：事件循环（loop）+回调（Python中可以驱动生成器完成同样效果）+epoll（IO多路复用）\n",
    "# asyncio 是Python用于解决异步io编程的一整套解决方案\n",
    "# tornado、gevent、twisted（scrapy、django、channels）\n",
    "\n",
    "# tornado（实现了web服务器）  ，django + flask 是传统的阻塞io的编程模型，不提供web服务器（只提供了简单的socket，方便我们调试） ，部署时需要搭配第三方实现了socket接口的（uwsgi, gunicoro+nginx）\n",
    "#tornado可以直接部署， 但还是搭配nginx+tornado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用asyncio\n",
    "import asyncio    # 可以简单的将asyncio简单的理解为协程池\n",
    "import time\n",
    "async def get_html(url):   # 定义一个协程\n",
    "    print(\"start get url\")\n",
    "    '''\n",
    "        下面的语句必须要加await，因为sleep(2)是一个耗时的操作，必须等待耗时对象完成后\n",
    "        其次，使用await后面要使用Awaitable对象，生成器就是一个Awaitable对象     _collections_abc 中\n",
    "    '''\n",
    "    await asyncio.sleep(2)  # 不能使用传统的time.sleep(2) 来实现等待， 因为time.sleep是一个同步阻塞的接口，同步阻塞的接口是不能用在协程中的\n",
    "    '''\n",
    "        根据之前协程和异步io章节中的讨论，await实际就是yield from的功能，所以这里我们可以知道，当执行到\n",
    "        await asyncio.sleep(2)的时候，实际进入了asyncio.sleep(2)这个协程中去执行耗时操作了，当该协程执行\n",
    "        完毕的时候，又返回到当前协程，继续执行剩下的操作\n",
    "    '''\n",
    "    \n",
    "    print(\"end get url\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    loop = asyncio.get_event_loop()   # 提供事件循环\n",
    "    loop.run_until_complete(get_html(\"http://www.imooc.com\"))   # 阻塞的方法，将协程放进去       \n",
    "    '''\n",
    "        理解为多线程中的join方法，会等待协程完成再进行之后的操作，同时还相当于使用start开启线程那样开启了协程\n",
    "        准确的来说也就是start和join的结合，\n",
    "    '''\n",
    "    print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 老版本的写法\n",
    "loop = asyncio.get_event_loop()\n",
    "try:\n",
    "    loop.run_until_complete(coro)\n",
    "finally:\n",
    "    loop.close()  # 使用loop.run_until_complete(coro)的时，必须使用 close关闭事件循环\n",
    "    \n",
    "# 在Python3.7后直接使用\n",
    "asyncio.run(coro) 代替"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cannot close a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-860c0312a594>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# 放入协程对象 一并提交给loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# 阻塞的方法，将协程人进来，asyncio.wait()接受一个可迭代对象\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/asyncio/base_events.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_forever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/asyncio/base_events.py\u001b[0m in \u001b[0;36mrun_forever\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This event loop is already running'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-860c0312a594>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/asyncio/unix_events.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finalizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_signal_handlers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/asyncio/selector_events.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot close a running event loop\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot close a running event loop"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start get url 7\n",
      "start get url 1\n",
      "start get url 5\n",
      "start get url 6\n",
      "start get url 8\n",
      "start get url 2\n",
      "start get url 9\n",
      "start get url 4\n",
      "start get url 3\n",
      "start get url 0\n",
      "end get url 7\n",
      "end get url 1\n",
      "end get url 5\n",
      "end get url 6\n",
      "end get url 8\n",
      "end get url 2\n",
      "end get url 9\n",
      "end get url 4\n",
      "end get url 3\n",
      "end get url 0\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "async def get_html(url):\n",
    "    print(\"start get url\", url)\n",
    "    '''\n",
    "        此处使用time.sleep(2)的话，就是同步的，他会将完整的get_html函数执行完一遍后再执行下一次，不是并发的\n",
    "        而使用了asyncio.sleep(2)的话 会返回一个future （与线程中一样会立即返回一个future）\n",
    "        \n",
    "        使用time.sleep()的话，实际上就变成了一个顺序执行的过程\n",
    "        \n",
    "        与不能同time.sleep(2)一起使用的理由一样，asyncio不能同pymysql使用想达到并发效果，是因为，pymysql接口是阻塞的，而协程是单线程的，只要有一个地方阻塞，就会整个阻塞等待下面完成，没有并发的效果\n",
    "        所以我们使用的时候一定要配合相应的异步库才能体现asyncio的并发\n",
    "        \n",
    "        asyncio 是不能配合requests库的    \n",
    "    '''\n",
    "    await asyncio.sleep(2)  # 不能使用传统的time.sleep(2) 来实现等待， 因为time.sleep是一个同步阻塞的接口，同步阻塞的接口是不能用在协程中的\n",
    "    print(\"end get url\", url)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    loop = asyncio.get_event_loop()   # 提供事件循环\n",
    "    try:\n",
    "        tasks = [get_html(i) for i in range(10)]  # 放入协程对象 一并提交给loop\n",
    "        loop.run_until_complete(asyncio.wait(tasks))   # 阻塞的方法，将协程人进来，asyncio.wait()接受一个可迭代对象\n",
    "        print(time.time()-start_time)\n",
    "    finally:\n",
    "        loop.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是被调用的函数\n",
      "我完成了调用\n",
      "1\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4dc3be694fe7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mawait_coroutine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "async def async_function():\n",
    "    print(\"我是被调用的函数\")\n",
    "    return 1\n",
    "\n",
    "async def await_coroutine():\n",
    "    result = await async_function()\n",
    "    print(\"我完成了调用\")\n",
    "    print(result)\n",
    "    \n",
    "await_coroutine().send(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取协程的返回值     线程中在使用线程池的时候会涉及到这个问题\n",
    "'''\n",
    "协程对象不能直接运行，在注册事件循环的时候，其实是run_until_complete方法将协程包装成为了一个任务（task）对象. \n",
    "task对象是Future类的子类，保存了协程运行后的状态，用于未来获取协程的结果\n",
    "\n",
    "所以，协程是可以直接放在 loop.run_until_complete(协程) 中，此时run_until_complete方法会自动将协程包装成为一个任务（task）\n",
    "对象，或者我们可以调用loop.creat_task(协程)创建任务，然后使用loop.run_until_complete(task)调用这些任务，好处是能够通过task\n",
    "对象，通过 task.result() 获取到协程的返回值（有return 的协程，没有return的时候，task得到的返回值是None）。\n",
    "'''\n",
    "import asyncio\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "async def get_html(url):\n",
    "    print(\"start get url\")\n",
    "    await asyncio.sleep(2)\n",
    "    return \"bobby\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    loop = asyncio.get_event_loop()\n",
    "    \"\"\"\n",
    "    loop中也提供了和ensure_future类似的方法--loop.create_task()\n",
    "    ensure_future接受一个协程对象 返回的是future对象  做的事情：实际包装为一个task，并将该协程注册到loop队列中\n",
    "    loop.create_task()返回的是一个task类型，它是future类型的子类\n",
    "        将asyncio理解为协程池，操作和线程池类似\n",
    "    以下将使用两种方式来实现协程的返回值获取\n",
    "    \"\"\"\n",
    "    # 方式1：\n",
    "    # get_future = asyncio.ensure_future(get_html(\"http://www.imooc.com\"))  # ensure_future 可以拿到一个future对象\n",
    "    # loop.run_until_complete(get_future)  # 接受的参数类型丰富， future 协程类型\n",
    "    # print(get_future.result())   # future和线程池中的future概念是一样的 可以同类理解\n",
    "    # 方式2：\n",
    "    task = loop.create_task(get_html(\"http://www.imooc.com\")) # 和asyncio.ensure_future()功能类似\n",
    "    loop.run_until_complete(task)\n",
    "    print(task.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "添加callback函数\n",
    "'''\n",
    "import asyncio\n",
    "import time\n",
    "from functools import partial\n",
    "'''\n",
    "用于将一个函数包装为另一个函数，如可以添加参数\n",
    "'''\n",
    "\n",
    "\n",
    "async def get_html(url):\n",
    "    print(\"start get url\")\n",
    "    await asyncio.sleep(2)\n",
    "    return \"bobby\"\n",
    "\n",
    "\n",
    "def call_back(url, future):  # 问题来了，如果call_back函数需要另外再接受一个参数，怎么办 使用partial类\n",
    "    print(\"send Email to tt\")\n",
    "    print(url)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    loop = asyncio.get_event_loop()\n",
    "    task = loop.create_task(get_html(\"http://www.imooc.com\"))\n",
    "    '''\n",
    "        因为add_done_callback函数会将future值传进调用的函数call_back中，所以call_back函数应该设置一个参数接受future\n",
    "        当callback函数要接受除了future之外的参数的时候，此时可以使用partial对函数进行包装\n",
    "        用法是：使用partial() 接受一个函数对象，以及参数（要注意接受的参数的位置，是放在首位的）\n",
    "    '''\n",
    "    task.add_done_callback(partial(call_back, \"http://www.imooc.com\"))\n",
    "    loop.run_until_complete(task)\n",
    "    '''\n",
    "    打印结果：\n",
    "            start get url\n",
    "            send Email to tt\n",
    "            http://www.imooc.com\n",
    "            bobby\n",
    "    '''\n",
    "    print(task.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# partial的用法\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def a(first_pa, second_pa):\n",
    "    print(first_pa)\n",
    "    print(second_pa)\n",
    "\n",
    "\n",
    "v = partial(a, 1)\n",
    "v(2) # 注意的是，partial接受的参数传递值的时候，是从第一个参数开始的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait 和 gather\n",
    "import asyncio\n",
    "from asyncio import FIRST_EXCEPTION, FIRST_COMPLETED\n",
    "import time\n",
    "\n",
    "'''\n",
    "wait在一次性提交多个任务的时候，就派上用场了\n",
    "# tasks = [get_html(\"http://www.imooc.com\") for i in range(10)]\n",
    "# loop.run_until_complete(asyncio.wait(tasks))   用于提交多个协程的时候 \n",
    "asyncio.wait()有return_when参数，可以设置\n",
    "\n",
    "对应线程池的wait，\n",
    "'''\n",
    "\n",
    "async def get_html(url):\n",
    "    print(\"start get url\")\n",
    "    await asyncio.sleep(2)\n",
    "    print(\"end get url\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    loop = asyncio.get_event_loop()\n",
    "    tasks = [get_html(\"http://www.imooc.com\") for i in range(10)]\n",
    "    loop.run_until_complete(asyncio.wait(tasks, return_when=FIRST_COMPLETED))\n",
    "    print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait 和 gather\n",
    "import asyncio\n",
    "from asyncio import FIRST_EXCEPTION, FIRST_COMPLETED\n",
    "import time\n",
    "\n",
    "\n",
    "async def get_html(url):\n",
    "    print(\"start get url\")\n",
    "    await asyncio.sleep(2)\n",
    "    print(\"end get url\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    loop = asyncio.get_event_loop()\n",
    "    tasks = [get_html(\"http://www.imooc.com\") for i in range(10)]\n",
    "    '''\n",
    "        asyncio.gather()是比asyncio.wait()方法更加高层的方法\n",
    "        和wait的区别：\n",
    "            更加高级\n",
    "            能将task进行分组\n",
    "        \n",
    "    '''\n",
    "    loop.run_until_complete(asyncio.gather(*tasks)) # 使用asyncio.gather的时候传递参数要使用解包 *\n",
    "    print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用gather对任务进行分组\n",
    "\n",
    "import asyncio\n",
    "from asyncio import FIRST_EXCEPTION, FIRST_COMPLETED\n",
    "import time\n",
    "\n",
    "\n",
    "async def get_html(url):\n",
    "    print(\"start get url\")\n",
    "    await asyncio.sleep(2)\n",
    "    print(\"end get url\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    loop = asyncio.get_event_loop()\n",
    "    # gather和wait的区别\n",
    "    # gather更加high-level\n",
    "    # 使用gathrer可以进行task分组\n",
    "    group1 = [get_html(\"http://projectsedu.com\") for i in range(2)]\n",
    "    group2 = [get_html(\"http://www.imooc.com\") for i in range(2)]\n",
    "    group1 = asyncio.gather(*group1)\n",
    "    group2 = asyncio.gather(*group2)\n",
    "    '''\n",
    "    这里使用group2.cancel()会报错，不知道为什么\n",
    "    '''\n",
    "    group2.cancel()  #  可以将整个分组二取消掉\n",
    "    '''\n",
    "        gather的灵活性更高，所以优先选择使用gather，\n",
    "        在某些定制型特别强的时候再去考虑使用wait方法\n",
    "    '''\n",
    "    loop.run_until_complete(asyncio.gather(group1, group2))\n",
    "    print(time.time() - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13-3 task取消和子协程调用原理\n",
    "\n",
    "#1. run_until_complete\n",
    "import asyncio\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_forever()\n",
    "'''\n",
    "loop.run_forever()和loop.run_until_complete()区别：\n",
    "loop.run_until_complete()会在指定的协程运行完成之后停止，但是run_forever不会，而是会一直运行\n",
    "loop.run_until_complete()在内部也是调用的run_forever，但是有一个回调函数，能够当协程完成的时候，终止loop\n",
    "'''\n",
    "loop.run_until_complete()\n",
    "#1. loop会被放到future中\n",
    "\n",
    "\n",
    "#2. 取消future  (task)\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def get_html(sleep_times):\n",
    "    print(\"waiting\")\n",
    "    await asyncio.sleep(sleep_times)\n",
    "    print(\"done after {}s\".format(sleep_times))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    task1 = get_html(2)\n",
    "    task2 = get_html(3)\n",
    "    task3 = get_html(3)\n",
    "\n",
    "    tasks = [task1, task2, task3]\n",
    "\n",
    "    loop = asyncio.get_event_loop()\n",
    "\n",
    "    try:\n",
    "        loop.run_until_complete(asyncio.wait(tasks))\n",
    "    except KeyboardInterrupt as e:  # 在外部按了ctrl+ c会触发该异常\n",
    "        all_tasks = asyncio.Task.all_tasks()\n",
    "        '''\n",
    "            asyncio.Task.all_tasks()表面看是直接调用的asyncio的Task，但是却能获得当前loop中的任务，\n",
    "            原理和之前的获取协程的返回值使用的asyncio.ensure_future()原理类似，在内部都使用了\n",
    "            if loop is None:\n",
    "                loop = events.get_event_loop() \n",
    "            当没有指定loop的时候，会去创建一个loop，而一个协程中只有一个loop，所以最后还是使用的同一个loop\n",
    "        '''\n",
    "        for task in all_tasks:\n",
    "            print(\"cancel task\")\n",
    "            print(task.cancel())  # 终止任务 ， 返回结果，True表示终止成功，False表示终止失败。 已经在运行中的是无法被终止的\n",
    "        loop.stop()  # 任务取消之后，stop loop\n",
    "        loop.run_forever()  # 在stop之后，一定要再次调用一次run_forever，否则会报异常\n",
    "    finally:\n",
    "        loop.close()  #  close 做的事情比stop的多"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![_20190.png](https://www.z4a.net/images/2019/09/27/_20190.png)\n",
    "![_20190927083350.png](https://www.z4a.net/images/2019/09/27/_20190927083350.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13-4 call_soon、call_at、call_later、call_soon_threadsafe\n",
    "\n",
    "import asyncio\n",
    "\n",
    "def callback(sleep_times):\n",
    "    print(\"sleep {} success\".format(sleep_times))\n",
    "\n",
    "#call_later, call_at\n",
    "if __name__ == \"__main__\":\n",
    "    loop = asyncio.get_event_loop()\n",
    "    '''\n",
    "        call_soon(回调的函数名, 参数)  这里是调用的是函数，而不是协程\n",
    "        call_soon的作用是即刻执行，所谓的即刻执行，是当队列中等待到下一个循环的时候就直接执行完成。\n",
    "    '''\n",
    "    loop.call_soon(callback, 2)\n",
    "    '''\n",
    "        此处必须使用run_forever进行启动，因为callback不是一个协程，而是一个函数\n",
    "        我们想直接启动loop，就可以使用run_forever，但是这样启动，loop就会一直进行循环而不会退出\n",
    "    '''\n",
    "    loop.run_forever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "def callback1(sleep_times):\n",
    "    print(\"callback1 sleep {} success\".format(sleep_times))\n",
    "    time.sleep(4)\n",
    "    print(\"callback1 end\")\n",
    "\n",
    "def callback2(sleep_times):\n",
    "    print(\"calllback2 sleep {} success\".format(sleep_times))\n",
    "    time.sleep(2)\n",
    "    print(\"callback2 end call\")\n",
    "\n",
    "#call_later, call_at\n",
    "if __name__ == \"__main__\":\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.call_soon(callback1, 2)\n",
    "    loop.call_soon(callback2, 3)\n",
    "    loop.run_forever()\n",
    "    \n",
    "    \n",
    "结果：\n",
    "callback1 sleep 2 success\n",
    "callback1 end\n",
    "calllback2 sleep 3 success\n",
    "callback2 end call\n",
    "\n",
    "'''\n",
    "可以发现call_soon()就是调用函数，并且等待该函数执行完成再执行其他的\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "def callback(sleep_times):\n",
    "    print(\"sleep {} success\".format(sleep_times))\n",
    "\n",
    "def stoploop(loop):\n",
    "    loop.stop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.call_soon(callback, 2)\n",
    "    loop.call_soon(stoploop, loop)  # 解决run_forever不会停止的办法，再添加一个call_soon在刚刚之后\n",
    "    loop.run_forever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call_later使用\n",
    "import asyncio\n",
    "\n",
    "def callback(sleep_times):\n",
    "    print(\"sleep {} success\".format(sleep_times))\n",
    "\n",
    "def stoploop(loop):\n",
    "    loop.stop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    loop = asyncio.get_event_loop()\n",
    "    '''\n",
    "    通过打印结果可见：\n",
    "    call_later(指定等待的时间，调用的方法，参数)\n",
    "    call_later是设置在等待某个时间后调用相应的函数\n",
    "    而call_soon则是当队列中等待到下一个循环的时候就直接执行完成。\n",
    "\n",
    "    '''\n",
    "    loop.call_later(2, callback, 2)\n",
    "    loop.call_later(1, callback, 1)\n",
    "    loop.call_later(3, callback, 3)\n",
    "    loop.call_soon(callback, 4)\n",
    "\n",
    "    # loop.call_soon(stoploop, loop)  # 解决run_forever不会停止的办法，再添加一个call_soon在刚刚之后\n",
    "    loop.run_forever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用call_at 设置在某个时间调用相应的函数\n",
    "import asyncio\n",
    "\n",
    "def callback(sleep_times, loop):\n",
    "    print(\"success time {}\".format(loop.time()))\n",
    "def stoploop(loop):\n",
    "    loop.stop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    loop = asyncio.get_event_loop()\n",
    "    now = loop.time()\n",
    "    '''\n",
    "    call_at是按照设定的时间执行相应的函数\n",
    "    但是这个时间必须是loop.time()得到的单调时间\n",
    "    '''\n",
    "    loop.call_at(now+2, callback, 2, loop)\n",
    "    loop.call_at(now+1, callback, 1, loop)\n",
    "    loop.call_at(now+3, callback, 3, loop)\n",
    "    # loop.call_soon(stoploop, loop)\n",
    "    loop.call_soon(callback, 4, loop)\n",
    "    loop.run_forever()\n",
    "    \n",
    "    \n",
    "    结果：\n",
    "    success time 41392.14\n",
    "    success time 41393.14\n",
    "    success time 41394.14\n",
    "    success time 41395.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_soon_threadsafe()方法，线程安全的\n",
    "提供该方法的目的是因为asyncio也提供了在多线程下的异步io解决方案，\n",
    "如在多线程的时候，在callback函数中解决一个变量，就可以涉及到线程安全的问题\n",
    "可以使用call_soon_threadsafe()来代替call_soon，在其内部调用了_wait_to_self()\n",
    "两者的使用方式是一致的，仅仅一个是多线程下的解决方案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>以上的几个方法都是asyncio中比较底层的方法，被在asyncio内部大量的调用，一般在我们的使用中是很少会用到的</font>\n",
    "</br>\n",
    "若将以上方法和协程同用，需要注意的是:call_later 和 call_at 设定的时间一定要使得调用该函数的时候在协程完成的时间之内，即在run_until_complete()结束之前完成对函数的调用，否则超出时间后，将不起作用，因为run_until_complete()会在调用协程结束后，自动结束loop，没有了loop，call_at 等方法无法执行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13-5 ThreadPollExecutor 和 asycio 完成阻塞 IO 请求\n",
    "'''\n",
    "将线程池和异步io结合起来\n",
    "\n",
    "asyncio是异步io编程的解决方案，异步io是包括多线程，进程以及协程的\n",
    "所以使用asyncio是可以在多线程，进程以及协程中使用的\n",
    "\n",
    "什么时候使用多线程：\n",
    "协程中是不能使用阻塞io的，但是某些时候，有的库或者接口只能提供阻塞的，此时我们就可以将这些阻塞io放到多线程中去调用，\n",
    "如pymysql和mysqlclient都是阻塞的，想在协程中强行使用这几个时，就可以使用多线程\n",
    "\n",
    "'''\n",
    "# 在asyncio中集成线程池\n",
    "#使用多线程：在携程中集成阻塞io\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import socket\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "\n",
    "def get_url(url):\n",
    "    #通过socket请求html\n",
    "    url = urlparse(url)\n",
    "    host = url.netloc\n",
    "    path = url.path\n",
    "    if path == \"\":\n",
    "        path = \"/\"\n",
    "\n",
    "    #建立socket连接\n",
    "    client = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    # client.setblocking(False)\n",
    "    client.connect((host, 80)) #阻塞不会消耗cpu\n",
    "\n",
    "    #不停的询问连接是否建立好， 需要while循环不停的去检查状态\n",
    "    #做计算任务或者再次发起其他的连接请求\n",
    "\n",
    "    client.send(\"GET {} HTTP/1.1\\r\\nHost:{}\\r\\nConnection:close\\r\\n\\r\\n\".format(path, host).encode(\"utf8\"))\n",
    "\n",
    "    data = b\"\"\n",
    "    while True:\n",
    "        d = client.recv(1024)\n",
    "        if d:\n",
    "            data += d\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    data = data.decode(\"utf8\")\n",
    "    html_data = data.split(\"\\r\\n\\r\\n\")[1]\n",
    "    print(html_data)\n",
    "    client.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    loop = asyncio.get_event_loop()\n",
    "    executor = ThreadPoolExecutor(3)\n",
    "    tasks = []\n",
    "    for url in range(20):\n",
    "        url = \"http://shop.projectsedu.com/goods/{}/\".format(url)\n",
    "        '''\n",
    "            loop下有一个run_in_executor(线程池, 接口函数名称, 参数)，接受一个线程池，需要添加在线程池中的函数，参数\n",
    "            run_in_executor()是立即执行并且返回的。\n",
    "            实现了使阻塞的代码在线程池中运行了\n",
    "            \n",
    "            性能还是线程的性能，只是能够在协程中使用阻塞io了\n",
    "        '''\n",
    "        task = loop.run_in_executor(executor, get_url, url)  # 立即执行并返回  返回一个task任务对象\n",
    "        tasks.append(task)  # 将任务对象放到列表中，之后使用run_until_complete直接调用\n",
    "    loop.run_until_complete(asyncio.wait(tasks))\n",
    "    print(\"last time:{}\".format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13-6 asyncio 模拟 http 请求\n",
    "\n",
    "# asyncio 没有提供http协议的接口 提供的是更加底层的tcp udp协议\n",
    "# aiohttp 可以搭建http服务器， 可以当做异步的request库\n",
    "import asyncio\n",
    "import socket\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "\n",
    "async def get_url(url):\n",
    "    # 通过socket请求html\n",
    "    url = urlparse(url)\n",
    "    host = url.netloc\n",
    "    path = url.path\n",
    "    if path == \"\":\n",
    "        path = \"/\"\n",
    "\n",
    "    # 建立socket连接\n",
    "    '''\n",
    "        asyncio.open_connection(host, 80)协程，让我们和服务端建立连接\n",
    "    '''\n",
    "    reader, writer = await asyncio.open_connection(host, 80)\n",
    "    writer.write(\"GET {} HTTP/1.1\\r\\nHost:{}\\r\\nConnection:close\\r\\n\\r\\n\".format(path, host).encode(\"utf8\"))\n",
    "    all_lines = []\n",
    "    '''\n",
    "        async for 语法：\n",
    "            将for\n",
    "    '''\n",
    "    async for raw_line in reader:\n",
    "        data = raw_line.decode(\"utf8\")\n",
    "        all_lines.append(data)\n",
    "    html = \"\\n\".join(all_lines)\n",
    "    return html\n",
    "\n",
    "\n",
    "async def main():\n",
    "    tasks = []\n",
    "    for url in range(20):\n",
    "        url = \"http://shop.projectsedu.com/goods/{}/\".format(url)\n",
    "        tasks.append(asyncio.ensure_future(get_url(url)))\n",
    "    for task in asyncio.as_completed(tasks):  # 和线程池中的方法一致，某个协程完成就返回一个值\n",
    "        result = await task\n",
    "        print(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.run_until_complete(main())\n",
    "    print('last time:{}'.format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13-7 future 和 task\n",
    "\n",
    "future是一个结果容器，会将结果放到该容器中，当结果容器运行完的时候，会调用一个callback函数\n",
    "Task 是future.Future的子类，功能实际上没有太大的变化，设计的时候在线程池中没有，但是在协程中就有是为什么呢：\n",
    "    实际上 Task是协程和future之间的桥梁，_step(self, exc=None)方法，在定义了一个协程之后，要想驱动该协程，必须对该协程\n",
    "    调用一次next，或者send让协程生效，在Task的__init__中有一个call_soon(self._step)会在loop开始的时候先调用一次_step方法，\n",
    "    _step方法中，做的事会先执行send(None)启动一下协程，之后还有一个处理StopIteration异常的逻辑\n",
    "    \n",
    "    这么设计是为了保证线程池，进程池，协程中的future接口尽量一致，然后为了适合协程，再设计了Task子类，来解决协程和线程之间\n",
    "    不一样的地方\n",
    "    \n",
    "asyncio也有future\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13-8 asyncio同步和通信\n",
    "\n",
    "单线程中是不需要锁的，\n",
    "\n",
    "import asyncio\n",
    "\n",
    "total = 0\n",
    "\n",
    "\n",
    "async def add():\n",
    "    global total\n",
    "    for i in range(1000000):\n",
    "        total += 1\n",
    "\n",
    "\n",
    "async def desc():\n",
    "    global total\n",
    "    for i in range(1000000):\n",
    "        total -= 1\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tasks = [add(), desc()]\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.run_until_complete(asyncio.wait(tasks))\n",
    "    print(total)\n",
    "\n",
    "'''\n",
    "使用协程是不需要借助锁来保证数据的安全的，\n",
    "因为协程中，凡是不是io，或yield 出去的值，协程都会将该段代码运行完毕后，在运行下一段代码\n",
    "协程的本质，凡是不涉及到io操作，和await的操作，他都会执行完当前段的代码，再执行其他的代码\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asyncio 提供了锁Lock ，也有其他的同步机制，和多线程的区别在于没有RLock，因为多线程才需要RLock，协程是单线程的，\n",
    "只需要一个Lock就行了。\n",
    "需要注意的是，在使用锁的地方，lock.acquire()的时候，需要使用await lock.acquire() 因为acquire()方法是使用@coroutine进行修饰\n",
    "的变成了协程，也就是上锁之后，我们是需要等待的。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用协程编程的时候，有些情况之下，还是需要用到同步机制的\n",
    "\n",
    "import asyncio\n",
    "from asyncio import Lock, Queue\n",
    "\n",
    "\n",
    "cache = {}  # url缓存\n",
    "lock = Lock()\n",
    "'''\n",
    "    通过Lock的实现，我们知道在协程中写库或者驱动的时候，想要做到高并发，一定不能是阻塞的，方式阻塞，使用yield from 或者 await\n",
    "    Python3.7.2中的已经统一使用await来完成了\n",
    "    Lock\n",
    "    \n",
    "    asyncio也提供了协程下的Queue，其中put get都是协程非阻塞的\n",
    "    提供Queue的目的是，Queue有个最大长度的参数，可以实现限流的目的。\n",
    "    平常用于协程之间的同行，因为是单线程的，可以直接定义一个全局变量queue\n",
    "    \n",
    "'''\n",
    "\n",
    "\n",
    "async def get_stuff(url):\n",
    "    \"\"\"\n",
    "    获取某个url，有的话直接返回，没有的话，调用协程去请求\n",
    "    :param url:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    async with lock:  # 实际就是 with await lock；   async with需要实现__awati__和__aenter__魔法方法\n",
    "        if url in cache:\n",
    "            return cache[url]\n",
    "        stuff = await aiohttp.request('GET', url)  # aiohttp可以理解为requests库的异步版本库\n",
    "        cache[url] = stuff\n",
    "        return stuff\n",
    "\n",
    "\n",
    "async def parse_stuff():\n",
    "    \"\"\"\n",
    "    需要使用get_stuff的数据，进行url解析\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    stuff = await get_stuff()\n",
    "    # do some parsing\n",
    "\n",
    "\n",
    "async def use_stuff():\n",
    "    \"\"\"\n",
    "    需要使用get_stuff的数据，\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    stuff = await get_stuff()\n",
    "    # use stuff to do something interesting\n",
    "\n",
    "\n",
    "tasks = [parse_stuff(), use_stuff()]\n",
    "\n",
    "\n",
    "'''\n",
    "问题：\n",
    "    如果get_stuff任务非常耗时的话，parse_stuff(), use_stuff()会同时运行起来，\n",
    "    去请求同一个url，而此时cache池中可以还没有该url,就会同时去执行aiohttp.request('GET', url)\n",
    "    但是这样两次请求的都是同一个url，这样是不好的\n",
    "    \n",
    "    可以考虑在get_stuff(url)中加一个锁，这样parse_stuff(), use_stuff()使用同一url的时候，\n",
    "    就不会当url没有的时候，都去执行aiohttp.request('GET', url)，请求两次\n",
    "    \n",
    "所以虽然协程中没有锁的概念，但是我们还是需要同步机制去避免一些情况，使用同步机制，将一段代码保护起来\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2019/9/27 11:09\n",
    "# @Author  : Skylor Tang\n",
    "# @Email   : \n",
    "# @File    : asyncio_sqider.py\n",
    "# @Software: PyCharm\n",
    "\n",
    "# 除了使用aiohttp提供了高并发的服务器端，还有一个sanic,基于asyncio 和 。。。 来实现的高并发的web服务器，号称性能接近go语言\n",
    "\n",
    "# asyncio爬虫、去重、入库（异步驱动入库）-- aiomysql\n",
    "\n",
    "\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import aiomysql\n",
    "import re\n",
    "from pyquery import PyQuery\n",
    "\n",
    "stopping = False\n",
    "start_url = \"https://www.jianshu.com\"\n",
    "waitting_urls = []  # 单线程，使用list做同行是没有问题的\n",
    "seen_urls = set()  # 小数据去重\n",
    "sem = asyncio.Semaphore(3)  # 用来设置并发度\n",
    "\n",
    "\n",
    "async def fetch(url, session):\n",
    "    \"\"\"\n",
    "    创建协程用于请求url\n",
    "    :param url:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    async with sem:\n",
    "        await asyncio.sleep(1) \n",
    "        # 配合sem完成并发量的控制\n",
    "        try:\n",
    "            async with session.get(url) as resp:\n",
    "                print(\"url status: {}\".format(resp.status))\n",
    "                if resp.status in [200, 201]:\n",
    "                    data = await resp.text()\n",
    "                    return data\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "def extract_urls(html):\n",
    "    \"\"\"\n",
    "    从html中解析url用。\n",
    "    因为是通过cpu完成解析的，所以是不会耗费io的，可以直接定义一个函数完成该工能\n",
    "    使用协程异步，要么是消耗io，自动切换，要么就是标记await，手动切换\n",
    "\n",
    "    完成功能：\n",
    "            从html中提取所有的url,在提取的同时过滤到爬取过的的以及不以http开头的\n",
    "    :param html:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    urls = []\n",
    "    pq = PyQuery(html)\n",
    "    for link in pq.items(\"a\"):\n",
    "        url = link.attr(\"href\")\n",
    "        if url and url.startswith(\"http\") and url not in seen_urls:\n",
    "            urls.append(url)\n",
    "            # 同时添加到待爬取的url列表中\n",
    "            waitting_urls.append(url)\n",
    "    return urls\n",
    "\n",
    "\n",
    "async def init_urls(url, session):\n",
    "    \"\"\"\n",
    "\n",
    "    完成功能：\n",
    "            请求html页面，然后解析html页面中的所有rul\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    html = await fetch(url, session)\n",
    "    seen_urls.add(url)\n",
    "    extract_urls(html)\n",
    "\n",
    "\n",
    "async def article_handler(url, session, pool):\n",
    "    \"\"\"\n",
    "    获取文章详情，并解析入库\n",
    "    :param url:\n",
    "    :param session:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    html = await fetch(url, session)\n",
    "    seen_urls.add(url)\n",
    "    # 在解析文章详情页的时候，如果有满足条件的url，也进行解析，放到waitting_urls中\n",
    "    extract_urls(html)\n",
    "    pq = PyQuery(html)\n",
    "    title = pq(\".title\").text()\n",
    "    print(title)\n",
    "\n",
    "    # 入库操作\n",
    "    async with pool.acquire() as conn:\n",
    "        async with conn.cursor() as cur:\n",
    "            # await cur.execute(\"SELECT 42;\")\n",
    "            insert_sql = \"insert into article_test(title) values('{}')\".format(title)\n",
    "            await cur.execute(insert_sql)\n",
    "\n",
    "\n",
    "async def consumer(pool):\n",
    "    \"\"\"\n",
    "    不停的从waitting_urls中获取数据，创建协程\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        # 将在此处使用session，并将需要使用该session的链接接受此session即可，\n",
    "        # 这样的话我们就可以共用一个session，而不需要每次请求的时候都重新建立一个连接\n",
    "        while not stopping:\n",
    "            # 下面的if逻辑，用于防止取过度，造成waitting_urls为空，异常，\n",
    "            # 但是，若此处使用的是asyncio提供的Queue队列，就不会产生此问题\n",
    "            if len(waitting_urls) == 0:\n",
    "                await asyncio.sleep(0.5)\n",
    "                continue\n",
    "\n",
    "            url = waitting_urls.pop()\n",
    "            print(\"start get url: {} \".format(url))\n",
    "            if re.match(\"http://.*?jianshu.com/\", url):\n",
    "                if url not in seen_urls:\n",
    "                    asyncio.ensure_future(article_handler(url, session, pool))\n",
    "                    # 爬取一个后停止30秒，反之过度访问\n",
    "                    await asyncio.sleep(30)\n",
    "            else:\n",
    "                if url not in seen_urls:\n",
    "                    asyncio.ensure_future(init_urls(url, session))\n",
    "\n",
    "\n",
    "async def main(loop):\n",
    "    \"\"\"\n",
    "    为什么使用main，而不直接将main中的逻辑放到下面，\n",
    "    因为pool，使用的是await，而await必须在协程中才能使用，所以必须用单独的协程进行包装\n",
    "\n",
    "    :param loop:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 等待mysql连接建立\n",
    "    pool = await aiomysql.create_pool(host='127.0.0.1', port=3306,\n",
    "                                      user='root', password='739230854tmj',\n",
    "                                      db='aiomysql_test', loop=loop,\n",
    "                                      charset='utf8', autocommit=True)\n",
    "    print(\"start\")\n",
    "    # async with aiohttp.ClientSession() as session:\n",
    "    #     asyncio.ensure_future(init_urls(start_url, session))\n",
    "    #     asyncio.ensure_future(consumer(pool))\n",
    "    # 在此处使用上面的语法是不合理的，因为下面的两条ensure_future()是异步的，提交完成后，\n",
    "    # 当前main协程就算完成了，就会跳出async with ， 此时session就失效了\n",
    "\n",
    "    # 使用下面一整段代替asyncio.ensure_future(init_urls(start_url, session))的功能\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        html = await fetch(start_url, session)\n",
    "        seen_urls.add(start_url)\n",
    "        extract_urls(html)\n",
    "\n",
    "    asyncio.ensure_future(consumer(pool))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    loop = asyncio.get_event_loop()\n",
    "    asyncio.ensure_future(main(loop))\n",
    "    loop.run_forever()\n",
    "    # 使用run_forever，会使得事件循环loop一直在调用当中"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
